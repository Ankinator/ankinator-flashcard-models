{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn import svm, metrics\n",
    "\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "#This cell contains the code to create the dataset\n",
    "\n",
    "import os\n",
    "from pypdfium2 import PdfDocument\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pdf_dir = \"./datasets/extractor_classifier/slides\"\n",
    "relevant_dir = \"./datasets/extractor_classifier/dataset_images/relevant\"\n",
    "not_relevant_dir = \"./datasets/extractor_classifier/dataset_images/not_relevant\"\n",
    "\n",
    "for filename in os.listdir(pdf_dir):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pdf_file = open(os.path.join(pdf_dir, filename), \"rb\")\n",
    "        pdf_document = PdfDocument(pdf_file)\n",
    "\n",
    "        for page_index, page_content in enumerate(pdf_document, 0):\n",
    "            bitmap = page_content.render(scale=2)\n",
    "            page_image = bitmap.to_pil()\n",
    "            plt.imshow(page_image)\n",
    "            plt.show()\n",
    "            input_str = input(\"Is this image relevant? (y/n)\")\n",
    "\n",
    "            if input_str.lower() == \"n\":\n",
    "                image_path = os.path.join(not_relevant_dir, f\"{filename}_{page_index}.png\")\n",
    "            else:\n",
    "                image_path = os.path.join(relevant_dir, f\"{filename}_{page_index}.png\")\n",
    "            page_image.save(image_path)\n",
    "\n",
    "        pdf_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import shutil\n",
    "import random\n",
    "\n",
    "root_dir = \"../../../datasets/extractor_classifier/dataset_images/\"\n",
    "\n",
    "# Define the percentage of data to use for each set\n",
    "train_percent = 0.7\n",
    "val_percent = 0.15\n",
    "test_percent = 0.15\n",
    "\n",
    "# Create a list of class names (assumes each class is a subfolder of root_dir)\n",
    "class_names = sorted(os.listdir(root_dir))\n",
    "\n",
    "if \".DS_Store\" in class_names:\n",
    "    class_names.remove(\".DS_Store\")\n",
    "\n",
    "# Define the output directories for the saved datasets\n",
    "train_output_dir = \"../../../datasets/extractor_classifier/train/\"\n",
    "val_output_dir = \"../../../datasets/extractor_classifier/validation/\"\n",
    "test_output_dir = \"../../../datasets/extractor_classifier/test/\"\n",
    "\n",
    "# Create the output directories if they don't already exist\n",
    "os.makedirs(train_output_dir, exist_ok=True)\n",
    "os.makedirs(val_output_dir, exist_ok=True)\n",
    "os.makedirs(test_output_dir, exist_ok=True)\n",
    "\n",
    "# Create train, validation, and test list\n",
    "train_list = []\n",
    "validation_list = []\n",
    "test_list = []\n",
    "\n",
    "# Split the data for each class into train, validation, and test sets\n",
    "for class_name in class_names:\n",
    "    # Get a list of all images for this class\n",
    "    images = os.listdir(root_dir + class_name)\n",
    "    random.Random(42).shuffle(images)\n",
    "\n",
    "    # Split the images into train, validation, and test sets\n",
    "    num_images = len(images)\n",
    "    num_train = int(train_percent * num_images)\n",
    "    num_val = int(val_percent * num_images)\n",
    "\n",
    "    train_images = images[:num_train]\n",
    "    val_images = images[num_train:num_train+num_val]\n",
    "    test_images = images[num_train+num_val:]\n",
    "\n",
    "    for image in train_images:\n",
    "        src_path = root_dir + class_name + \"/\" + image\n",
    "        label = class_names.index(class_name)\n",
    "        train_list.append((Image.open(src_path), label))\n",
    "\n",
    "    for image in val_images:\n",
    "        src_path = root_dir + class_name + \"/\" + image\n",
    "        label = class_names.index(class_name)\n",
    "        validation_list.append((Image.open(src_path), label))\n",
    "\n",
    "    for image in test_images:\n",
    "        src_path = root_dir + class_name + \"/\" + image\n",
    "        label = class_names.index(class_name)\n",
    "        test_list.append((Image.open(src_path), label))\n",
    "\n",
    "# Save the train dataset\n",
    "for image, label in train_list:\n",
    "    class_name = class_names[label]\n",
    "    output_path = os.path.join(train_output_dir, class_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    image_filename = os.path.splitext(os.path.basename(image.filename))[0] + \".jpg\"\n",
    "    shutil.copyfile(image.filename, os.path.join(output_path, image_filename))\n",
    "\n",
    "# Save the validation dataset\n",
    "for image, label in validation_list:\n",
    "    class_name = class_names[label]\n",
    "    output_path = os.path.join(val_output_dir, class_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    image_filename = os.path.splitext(os.path.basename(image.filename))[0] + \".jpg\"\n",
    "    shutil.copyfile(image.filename, os.path.join(output_path, image_filename))\n",
    "\n",
    "# Save the test dataset\n",
    "for image, label in test_list:\n",
    "    class_name = class_names[label]\n",
    "    output_path = os.path.join(test_output_dir, class_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    image_filename = os.path.splitext(os.path.basename(image.filename))[0] + \".jpg\"\n",
    "    shutil.copyfile(image.filename, os.path.join(output_path, image_filename))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import torchvision.transforms as T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# WIP data augmentation\n",
    "\n",
    "for image, label in train_list:\n",
    "        image_filename = os.path.splitext(os.path.basename(image.filename))[0] + \"_resized.jpg\"\n",
    "        output_path = os.path.join(train_augmented_output_dir, label, image_filename)\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        augmented_image.save(output_path)\n",
    "\n",
    "resized_images = [T.Resize(size=size)(the_image) for size in [32,128,224]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class ExtractorClassifierDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.resize_image = transforms.Resize((256, 256), antialias=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self. data[idx]\n",
    "        image_tensor = self.to_tensor(image)\n",
    "        image_tensor = self.resize_image(image_tensor)\n",
    "        image_tensor = image_tensor/255\n",
    "        label_tensor = torch.zeros(4)\n",
    "        label_tensor[label] = 1\n",
    "        return image_tensor, label_tensor\n",
    "\n",
    "# Define the train/validation/test datasets\n",
    "train_data = ExtractorClassifierDataset(train_list)\n",
    "validation_data = ExtractorClassifierDataset(validation_list)\n",
    "test_data = ExtractorClassifierDataset(test_list)\n",
    "\n",
    "# Define the dataloaders for each dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, )\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)"
=======
    "# Define hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001"
>>>>>>> Stashed changes
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Set the device\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device =  \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\" # Use M1 Mac GPU\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class ExtractorClassifierDataset(Dataset):\n",
    "    def __init__(self, data, resize_shape = (256,256)):\n",
    "        self.data = data\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.resize_image = transforms.Resize(resize_shape, antialias=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self. data[idx]\n",
    "        image_tensor = self.to_tensor(image)\n",
    "        image_tensor = self.resize_image(image_tensor)\n",
    "        image_tensor = image_tensor/255\n",
    "        label_tensor = torch.zeros(2)\n",
    "        label_tensor[label] = 1\n",
    "        return image_tensor, label_tensor\n",
    "\n",
    "data_dir = \"../../../datasets/extractor_classifier/\"\n",
    "\n",
    "train_list = []\n",
    "validation_list = []\n",
    "test_list = []\n",
    "\n",
    "for class_name in (\"relevant\", \"not_relevant\"):\n",
    "    if class_name == \"relevant\":\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "\n",
    "    for image in os.listdir(f\"{data_dir}/train/{class_name}\"):\n",
    "        src_path = f\"{data_dir}/train/{class_name}/{image}\"\n",
    "        train_list.append((Image.open(src_path), label))\n",
    "\n",
    "    for image in os.listdir(f\"{data_dir}/validation/{class_name}\"):\n",
    "        src_path = f\"{data_dir}/validation/{class_name}/{image}\"\n",
    "        validation_list.append((Image.open(src_path), label))\n",
    "\n",
    "    for image in os.listdir(f\"{data_dir}/test/{class_name}\"):\n",
    "        src_path = f\"{data_dir}/test/{class_name}/{image}\"\n",
    "        test_list.append((Image.open(src_path), label))\n",
    "\n",
    "# Define the train/validation/test datasets\n",
    "train_data = ExtractorClassifierDataset(train_list)\n",
    "validation_data = ExtractorClassifierDataset(validation_list)\n",
    "test_data = ExtractorClassifierDataset(test_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Define the dataloaders for each dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, )\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "class Resnet50Model(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(Resnet50Model, self).__init__()\n",
    "        self.resnet_model = resnet50(pretrained=pretrained)\n",
    "        self.fc = nn.Linear(in_features=1000, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet_model(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, test_loader, criterion, optimizer, epochs):\n",
    "    # Move the model to the device\n",
    "    model.to(device)\n",
    "\n",
    "    # Define variables to track the best validation accuracy and the corresponding model state\n",
    "    best_valid_acc = 0.0\n",
    "    best_model_state = None\n",
    "    train_loss_values = []\n",
    "    valid_loss_values = []\n",
    "    train_acc_values = []\n",
    "    valid_acc_values = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Train the model for one epoch\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_loss_values.append(train_loss)\n",
    "        train_acc = train_correct / train_total\n",
    "        train_acc_values.append(train_acc)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        valid_loss = 0.0\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                valid_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                _, labels = torch.max(labels.data, 1)\n",
    "                valid_correct += (predicted == labels).sum().item()\n",
    "                valid_total += labels.size(0)\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_acc = valid_correct / valid_total\n",
    "        valid_loss_values.append(valid_loss)\n",
    "        valid_acc_values.append(valid_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "              f\"Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.4f} - \"\n",
    "              f\"Valid Loss: {valid_loss:.4f} - Valid Acc: {valid_acc:.4f}\")\n",
    "\n",
    "        validate_model(model)\n",
    "\n",
    "        # Save the model state if the current validation accuracy is better than the previous best\n",
    "        if valid_acc > best_valid_acc:\n",
    "            best_valid_acc = valid_acc\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    # Load the best model state and evaluate on the test set\n",
    "    model.load_state_dict(best_model_state)\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "    test_acc = test_correct / test_total\n",
    "\n",
    "    print(f\"Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "    return model, train_loss_values, train_acc_values, valid_loss_values, valid_acc_values\n",
    "\n",
    "def validate_model(model):\n",
    "    model.to(device)\n",
    "    y_validation = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            y_validation.extend(labels.detach().cpu().numpy())\n",
    "            y_pred.extend(predicted.detach().cpu().numpy())\n",
    "    print(f\"Accuracy: {metrics.accuracy_score(y_validation, y_pred)}\")\n",
    "    print(classification_report(y_validation, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resnet_model = Resnet50Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "if os.path.isfile(\"model_results/resnet50_model_50.pt\"):\n",
    "    resnet_model.load_state_dict(torch.load(\"model_results/resnet50_model_50.pt\", map_location=torch.device(device)))\n",
    "    validate_model(resnet_model)\n",
    "else:\n",
    "    print(\"Train model\")\n",
    "    model, train_loss_values, train_accuracy_values, validation_loss_values, validation_accuracy_values = train(resnet_model, train_loader, validation_loader, test_loader, criterion, optimizer, 50)\n",
    "    torch.save(model.state_dict(), \"model_results/resnet50_model_50.pt\")\n",
    "    np.save(\"model_results/resnet50_model_50_train_loss\", train_loss_values)\n",
    "    np.save(\"model_results/resnet50_model_50_train_acc\", train_accuracy_values)\n",
    "    np.save(\"model_results/resnet50_model_50_valid_loss\", validation_loss_values)\n",
    "    np.save(\"model_results/resnet50_model_50_valid_acc\", validation_accuracy_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
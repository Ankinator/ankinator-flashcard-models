{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn import svm, metrics\n",
    "\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Set the device\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device =  \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\" # Use M1 Mac GPU\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class ExtractorClassifierDataset(Dataset):\n",
    "    def __init__(self, data, resize_shape = (256,256)):\n",
    "        self.data = data\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.resize_image = transforms.Resize(resize_shape, antialias=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self. data[idx]\n",
    "        image_tensor = self.to_tensor(image)\n",
    "        image_tensor = self.resize_image(image_tensor)\n",
    "        image_tensor = image_tensor/255\n",
    "        label_tensor = torch.zeros(2)\n",
    "        label_tensor[label] = 1\n",
    "        return image_tensor, label_tensor\n",
    "\n",
    "data_dir = \"../../../datasets/extractor_classifier/\"\n",
    "\n",
    "train_list = []\n",
    "validation_list = []\n",
    "test_list = []\n",
    "\n",
    "for class_name in (\"relevant\", \"not_relevant\"):\n",
    "    if class_name == \"relevant\":\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "\n",
    "    for image in os.listdir(f\"{data_dir}/train/{class_name}\"):\n",
    "        src_path = f\"{data_dir}/train/{class_name}/{image}\"\n",
    "        train_list.append((Image.open(src_path), label))\n",
    "\n",
    "    for image in os.listdir(f\"{data_dir}/validation/{class_name}\"):\n",
    "        src_path = f\"{data_dir}/validation/{class_name}/{image}\"\n",
    "        validation_list.append((Image.open(src_path), label))\n",
    "\n",
    "    for image in os.listdir(f\"{data_dir}/test/{class_name}\"):\n",
    "        src_path = f\"{data_dir}/test/{class_name}/{image}\"\n",
    "        test_list.append((Image.open(src_path), label))\n",
    "\n",
    "# Define the train/validation/test datasets\n",
    "train_data = ExtractorClassifierDataset(train_list)\n",
    "validation_data = ExtractorClassifierDataset(validation_list)\n",
    "test_data = ExtractorClassifierDataset(test_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Define the dataloaders for each dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, )\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "class Resnet50Model(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(Resnet50Model, self).__init__()\n",
    "        self.resnet_model = resnet50(pretrained=pretrained)\n",
    "        self.fc = nn.Linear(in_features=1000, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet_model(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, test_loader, criterion, optimizer, epochs):\n",
    "    # Move the model to the device\n",
    "    model.to(device)\n",
    "\n",
    "    # Define variables to track the best validation accuracy and the corresponding model state\n",
    "    best_valid_acc = 0.0\n",
    "    best_model_state = None\n",
    "    train_loss_values = []\n",
    "    valid_loss_values = []\n",
    "    train_acc_values = []\n",
    "    valid_acc_values = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Train the model for one epoch\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_loss_values.append(train_loss)\n",
    "        train_acc = train_correct / train_total\n",
    "        train_acc_values.append(train_acc)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        valid_loss = 0.0\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                valid_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                _, labels = torch.max(labels.data, 1)\n",
    "                valid_correct += (predicted == labels).sum().item()\n",
    "                valid_total += labels.size(0)\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_acc = valid_correct / valid_total\n",
    "        valid_loss_values.append(valid_loss)\n",
    "        valid_acc_values.append(valid_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "              f\"Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.4f} - \"\n",
    "              f\"Valid Loss: {valid_loss:.4f} - Valid Acc: {valid_acc:.4f}\")\n",
    "\n",
    "        validate_model(model)\n",
    "\n",
    "        # Save the model state if the current validation accuracy is better than the previous best\n",
    "        if valid_acc > best_valid_acc:\n",
    "            best_valid_acc = valid_acc\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    # Load the best model state and evaluate on the test set\n",
    "    model.load_state_dict(best_model_state)\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "    test_acc = test_correct / test_total\n",
    "\n",
    "    print(f\"Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "    return model, train_loss_values, train_acc_values, valid_loss_values, valid_acc_values\n",
    "\n",
    "def validate_model(model):\n",
    "    model.to(device)\n",
    "    y_validation = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            y_validation.extend(labels.detach().cpu().numpy())\n",
    "            y_pred.extend(predicted.detach().cpu().numpy())\n",
    "    print(f\"Accuracy: {metrics.accuracy_score(y_validation, y_pred)}\")\n",
    "    print(classification_report(y_validation, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resnet_model = Resnet50Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "if os.path.isfile(\"model_results/resnet50_model_50.pt\"):\n",
    "    resnet_model.load_state_dict(torch.load(\"model_results/resnet50_model_50.pt\", map_location=torch.device(device)))\n",
    "    validate_model(resnet_model)\n",
    "else:\n",
    "    print(\"Train model\")\n",
    "    model, train_loss_values, train_accuracy_values, validation_loss_values, validation_accuracy_values = train(resnet_model, train_loader, validation_loader, test_loader, criterion, optimizer, 50)\n",
    "    torch.save(model.state_dict(), \"model_results/resnet50_model_50.pt\")\n",
    "    np.save(\"model_results/resnet50_model_50_train_loss\", train_loss_values)\n",
    "    np.save(\"model_results/resnet50_model_50_train_acc\", train_accuracy_values)\n",
    "    np.save(\"model_results/resnet50_model_50_valid_loss\", validation_loss_values)\n",
    "    np.save(\"model_results/resnet50_model_50_valid_acc\", validation_accuracy_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T09:28:38.675371Z",
     "end_time": "2023-05-03T09:28:46.440408Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T09:28:56.734820Z",
     "end_time": "2023-05-03T09:28:56.911897Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('flashcards_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T09:28:57.115014Z",
     "end_time": "2023-05-03T09:28:57.233474Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0.1  Unnamed: 0  \\\n0                0           0   \n1                1           1   \n2                2           2   \n3                3           3   \n4                4           4   \n...            ...         ...   \n4196          4985        4985   \n4197          4986        4986   \n4198          4987        4987   \n4199          4988        4988   \n4200          4989        4989   \n\n                                             nfld_Front  \\\n0                   What is the Scrum process Framework   \n1                           What are the roles in scrum   \n2                          What are the events in Scrum   \n3                       What are the artifacts in Scrum   \n4             What's the main role of the Product Owner   \n...                                                 ...   \n4196  How are cost plus and fixed fee contracts diff...   \n4197        When is quality assessed in Agile projects?   \n4198  When creating the work breakdown structure a t...   \n4199                       Agile Team Responsibilities?   \n4200        What does it mean to use the budgeted rate?   \n\n                                              nfld_Back            nid  \\\n0              \\nTransparency\\nInspection\\nAdaptation\\n  1390319421487   \n1     \\nProduct Owner (PO)\\nScrum Master (SM)\\nDevel...  1390319485342   \n2     \\nSprint Planning\\nDaily Scrum\\nSprint review\\...  1390319607681   \n3     \\nProduct Backlog\\nProduct Burn-up/down chart ...  1390319686841   \n4     Translate the business needs in the product ba...  1393853787833   \n...                                                 ...            ...   \n4196  Cost plus is good for evolving workFixed fee i...  1666621607498   \n4197  Frequently, through built-in steps throughout ...  1666621885435   \n4198  Inform them that this is known as a planning p...  1666627163918   \n4199  Product Owner - represents customers, accounta...  1666628126743   \n4200  Variances atypical - this means use the EAC fo...  1666640852028   \n\n                   cdeck                                              nflds  \n0                  Scrum  ['What is the Scrum process Framework', '<ul>\\...  \n1                  Scrum  ['What are the roles in scrum', '<ul>\\n<li>Pro...  \n2                  Scrum  ['What are the events in Scrum', '<ul>\\n<li>Sp...  \n3                  Scrum  ['What are the artifacts in Scrum', '<ul>\\n<li...  \n4                  Scrum  [\"What's the main role of the Product Owner\", ...  \n...                  ...                                                ...  \n4196  Z PMP detail areas  ['How are cost plus and fixed fee contracts di...  \n4197  Z PMP detail areas  ['When is quality assessed in Agile projects?'...  \n4198  Z PMP detail areas  ['&nbsp;<span style=\"color: rgb(51, 51, 51); f...  \n4199  Z PMP detail areas  ['Agile Team Responsibilities?', 'Product Owne...  \n4200  Z PMP detail areas  ['What does it mean to use the budgeted rate?'...  \n\n[4201 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>nfld_Front</th>\n      <th>nfld_Back</th>\n      <th>nid</th>\n      <th>cdeck</th>\n      <th>nflds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>What is the Scrum process Framework</td>\n      <td>\\nTransparency\\nInspection\\nAdaptation\\n</td>\n      <td>1390319421487</td>\n      <td>Scrum</td>\n      <td>['What is the Scrum process Framework', '&lt;ul&gt;\\...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>What are the roles in scrum</td>\n      <td>\\nProduct Owner (PO)\\nScrum Master (SM)\\nDevel...</td>\n      <td>1390319485342</td>\n      <td>Scrum</td>\n      <td>['What are the roles in scrum', '&lt;ul&gt;\\n&lt;li&gt;Pro...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>What are the events in Scrum</td>\n      <td>\\nSprint Planning\\nDaily Scrum\\nSprint review\\...</td>\n      <td>1390319607681</td>\n      <td>Scrum</td>\n      <td>['What are the events in Scrum', '&lt;ul&gt;\\n&lt;li&gt;Sp...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>What are the artifacts in Scrum</td>\n      <td>\\nProduct Backlog\\nProduct Burn-up/down chart ...</td>\n      <td>1390319686841</td>\n      <td>Scrum</td>\n      <td>['What are the artifacts in Scrum', '&lt;ul&gt;\\n&lt;li...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>What's the main role of the Product Owner</td>\n      <td>Translate the business needs in the product ba...</td>\n      <td>1393853787833</td>\n      <td>Scrum</td>\n      <td>[\"What's the main role of the Product Owner\", ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4196</th>\n      <td>4985</td>\n      <td>4985</td>\n      <td>How are cost plus and fixed fee contracts diff...</td>\n      <td>Cost plus is good for evolving workFixed fee i...</td>\n      <td>1666621607498</td>\n      <td>Z PMP detail areas</td>\n      <td>['How are cost plus and fixed fee contracts di...</td>\n    </tr>\n    <tr>\n      <th>4197</th>\n      <td>4986</td>\n      <td>4986</td>\n      <td>When is quality assessed in Agile projects?</td>\n      <td>Frequently, through built-in steps throughout ...</td>\n      <td>1666621885435</td>\n      <td>Z PMP detail areas</td>\n      <td>['When is quality assessed in Agile projects?'...</td>\n    </tr>\n    <tr>\n      <th>4198</th>\n      <td>4987</td>\n      <td>4987</td>\n      <td>When creating the work breakdown structure a t...</td>\n      <td>Inform them that this is known as a planning p...</td>\n      <td>1666627163918</td>\n      <td>Z PMP detail areas</td>\n      <td>['&amp;nbsp;&lt;span style=\"color: rgb(51, 51, 51); f...</td>\n    </tr>\n    <tr>\n      <th>4199</th>\n      <td>4988</td>\n      <td>4988</td>\n      <td>Agile Team Responsibilities?</td>\n      <td>Product Owner - represents customers, accounta...</td>\n      <td>1666628126743</td>\n      <td>Z PMP detail areas</td>\n      <td>['Agile Team Responsibilities?', 'Product Owne...</td>\n    </tr>\n    <tr>\n      <th>4200</th>\n      <td>4989</td>\n      <td>4989</td>\n      <td>What does it mean to use the budgeted rate?</td>\n      <td>Variances atypical - this means use the EAC fo...</td>\n      <td>1666640852028</td>\n      <td>Z PMP detail areas</td>\n      <td>['What does it mean to use the budgeted rate?'...</td>\n    </tr>\n  </tbody>\n</table>\n<p>4201 rows √ó 7 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T09:28:57.409760Z",
     "end_time": "2023-05-03T09:28:57.487292Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0','Unnamed: 0.1'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T09:28:58.796065Z",
     "end_time": "2023-05-03T09:28:58.832761Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                             nfld_Front  \\\n4196  How are cost plus and fixed fee contracts diff...   \n4197        When is quality assessed in Agile projects?   \n4198  When creating the work breakdown structure a t...   \n4199                       Agile Team Responsibilities?   \n4200        What does it mean to use the budgeted rate?   \n\n                                              nfld_Back            nid  \\\n4196  Cost plus is good for evolving workFixed fee i...  1666621607498   \n4197  Frequently, through built-in steps throughout ...  1666621885435   \n4198  Inform them that this is known as a planning p...  1666627163918   \n4199  Product Owner - represents customers, accounta...  1666628126743   \n4200  Variances atypical - this means use the EAC fo...  1666640852028   \n\n                   cdeck                                              nflds  \n4196  Z PMP detail areas  ['How are cost plus and fixed fee contracts di...  \n4197  Z PMP detail areas  ['When is quality assessed in Agile projects?'...  \n4198  Z PMP detail areas  ['&nbsp;<span style=\"color: rgb(51, 51, 51); f...  \n4199  Z PMP detail areas  ['Agile Team Responsibilities?', 'Product Owne...  \n4200  Z PMP detail areas  ['What does it mean to use the budgeted rate?'...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nfld_Front</th>\n      <th>nfld_Back</th>\n      <th>nid</th>\n      <th>cdeck</th>\n      <th>nflds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4196</th>\n      <td>How are cost plus and fixed fee contracts diff...</td>\n      <td>Cost plus is good for evolving workFixed fee i...</td>\n      <td>1666621607498</td>\n      <td>Z PMP detail areas</td>\n      <td>['How are cost plus and fixed fee contracts di...</td>\n    </tr>\n    <tr>\n      <th>4197</th>\n      <td>When is quality assessed in Agile projects?</td>\n      <td>Frequently, through built-in steps throughout ...</td>\n      <td>1666621885435</td>\n      <td>Z PMP detail areas</td>\n      <td>['When is quality assessed in Agile projects?'...</td>\n    </tr>\n    <tr>\n      <th>4198</th>\n      <td>When creating the work breakdown structure a t...</td>\n      <td>Inform them that this is known as a planning p...</td>\n      <td>1666627163918</td>\n      <td>Z PMP detail areas</td>\n      <td>['&amp;nbsp;&lt;span style=\"color: rgb(51, 51, 51); f...</td>\n    </tr>\n    <tr>\n      <th>4199</th>\n      <td>Agile Team Responsibilities?</td>\n      <td>Product Owner - represents customers, accounta...</td>\n      <td>1666628126743</td>\n      <td>Z PMP detail areas</td>\n      <td>['Agile Team Responsibilities?', 'Product Owne...</td>\n    </tr>\n    <tr>\n      <th>4200</th>\n      <td>What does it mean to use the budgeted rate?</td>\n      <td>Variances atypical - this means use the EAC fo...</td>\n      <td>1666640852028</td>\n      <td>Z PMP detail areas</td>\n      <td>['What does it mean to use the budgeted rate?'...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T12:30:54.098464Z",
     "start_time": "2023-04-28T12:30:54.089928Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tx = df.query('nid == 1666621607498').nfld_Back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.15.0-py3-none-any.whl (2.0 MB)\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m20.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: requests<3,>=2.0.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from wandb) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from wandb) (4.5.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: setuptools in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from wandb) (50.3.2)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: PyYAML in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.21.0-py2.py3-none-any.whl (199 kB)\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m199.5/199.5 kB\u001B[0m \u001B[31m29.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting GitPython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m184.3/184.3 kB\u001B[0m \u001B[31m29.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25hCollecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from wandb) (4.22.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m62.7/62.7 kB\u001B[0m \u001B[31m11.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: pathtools\n",
      "  Building wheel for pathtools (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8785 sha256=c8b22f170065ad9e82c3800a8ff3fa8c03045fb671ffe80a3033ae759bb114bf\n",
      "  Stored in directory: /pfs/data5/home/ma/ma_ma/ma_ptyagi/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
      "Successfully built pathtools\n",
      "Installing collected packages: pathtools, appdirs, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
      "\u001B[33m  WARNING: The scripts wandb and wb are installed in '/home/ma/ma_ma/ma_ptyagi/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\n",
      "\u001B[0mSuccessfully installed GitPython-3.1.31 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.21.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.0\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m474.6/474.6 kB\u001B[0m \u001B[31m17.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m212.2/212.2 kB\u001B[0m \u001B[31m36.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m132.9/132.9 kB\u001B[0m \u001B[31m23.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pandas in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from datasets) (2023.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /pfs/data5/home/ma/ma_ma/ma_ptyagi/.local/lib/python3.9/site-packages (from datasets) (0.14.1)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Downloading pyarrow-11.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m34.9/34.9 MB\u001B[0m \u001B[31m51.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: requests>=2.19.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from datasets) (1.23.5)\n",
      "Collecting dill<0.3.7,>=0.3.0\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m110.5/110.5 kB\u001B[0m \u001B[31m18.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: aiohttp in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: packaging in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: filelock in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.10.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, pyarrow, dill, responses, multiprocess, datasets\n",
      "\u001B[33m  WARNING: The script plasma_store is installed in '/home/ma/ma_ma/ma_ptyagi/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33m  WARNING: The script datasets-cli is installed in '/home/ma/ma_ma/ma_ptyagi/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\n",
      "\u001B[0mSuccessfully installed datasets-2.12.0 dill-0.3.6 multiprocess-0.70.14 pyarrow-11.0.0 responses-0.18.0 xxhash-3.2.0\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-03T09:31:21.340287Z",
     "end_time": "2023-05-03T09:31:57.140121Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 09:31:35.913321: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import load_dataset, load_metric, list_metrics,Dataset, DatasetDict\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollator, T5ForConditionalGeneration, T5TokenizerFast, T5Tokenizer, EvalPrediction, Trainer, TrainingArguments\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import dataclasses\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mpranav-tyagi-19\u001B[0m (\u001B[33mankinator\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=t5-e2e\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "%env WANDB_PROJECT=t5-e2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b610cd97c084a60827cf9bc1dd955a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-03T09:29:13.454396Z",
     "end_time": "2023-05-03T09:29:13.462345Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df[['nfld_Back','nfld_Front']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-03T09:29:13.991038Z",
     "end_time": "2023-05-03T09:29:14.028928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7j/mf5p4rjs4pv7s2ctxyh2kzyr0000gn/T/ipykernel_6836/944964238.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.rename(columns={\"nfld_Back\":\"context\",\"nfld_Front\":\"questions\"},inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df1.rename(columns={\"nfld_Back\":\"context\",\"nfld_Front\":\"questions\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-03T09:29:14.664456Z",
     "end_time": "2023-05-03T09:29:14.687718Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7j/mf5p4rjs4pv7s2ctxyh2kzyr0000gn/T/ipykernel_6836/3016100074.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-03T09:29:15.461509Z",
     "end_time": "2023-05-03T09:29:19.423246Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/sap_sr/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df1, test_size=0.2)\n",
    "train, valid = train_test_split(train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>{{c21::economies of scale}}{{c21::better produ...</td>\n",
       "      <td>What are the advantages of a capital intensive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1. The values of the CPU registers.2. The proc...</td>\n",
       "      <td>What state information needs to be saved durin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Unanimity - everyone agreesMajority - 50% agre...</td>\n",
       "      <td>What are types of voting?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>A bit given to each entry in the page table. T...</td>\n",
       "      <td>What is a reference bit?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>Release management</td>\n",
       "      <td>What management makes new and changed services...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>Take action</td>\n",
       "      <td>These answer what question in the continual im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>With a local replacement protocol, a process (...</td>\n",
       "      <td>How can the system's page replacement protocol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3903</th>\n",
       "      <td>Working together collaboratively</td>\n",
       "      <td>What does problem-solving look like?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>idea generation ‚Üí idea exploration ‚Üí product d...</td>\n",
       "      <td>What are the four phases of product development?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>The operating system could ask the supporting ...</td>\n",
       "      <td>How might an operating system test the validit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>826 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "1470  {{c21::economies of scale}}{{c21::better produ...   \n",
       "341   1. The values of the CPU registers.2. The proc...   \n",
       "4001  Unanimity - everyone agreesMajority - 50% agre...   \n",
       "779   A bit given to each entry in the page table. T...   \n",
       "2126                                 Release management   \n",
       "...                                                 ...   \n",
       "2371                                        Take action   \n",
       "800   With a local replacement protocol, a process (...   \n",
       "3903                   Working together collaboratively   \n",
       "1336  idea generation ‚Üí idea exploration ‚Üí product d...   \n",
       "1190  The operating system could ask the supporting ...   \n",
       "\n",
       "                                              questions  \n",
       "1470  What are the advantages of a capital intensive...  \n",
       "341   What state information needs to be saved durin...  \n",
       "4001                          What are types of voting?  \n",
       "779                            What is a reference bit?  \n",
       "2126  What management makes new and changed services...  \n",
       "...                                                 ...  \n",
       "2371  These answer what question in the continual im...  \n",
       "800   How can the system's page replacement protocol...  \n",
       "3903               What does problem-solving look like?  \n",
       "1336   What are the four phases of product development?  \n",
       "1190  How might an operating system test the validit...  \n",
       "\n",
       "[826 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_train = Dataset.from_pandas(train)\n",
    "raw_valid = Dataset.from_pandas(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict = {'train' : raw_train\n",
    "    ,'validation' : raw_valid}\n",
    "\n",
    "raw_text = DatasetDict(ds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'questions', '__index_level_0__'],\n",
       "        num_rows: 2478\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'questions', '__index_level_0__'],\n",
       "        num_rows: 826\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global user.email \"pranav.tyagi.19@gmail.com\"\n",
    "!git config --global user.name \"pranav1305\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-03T09:47:25.175640Z",
     "end_time": "2023-05-03T09:47:26.195312Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/sap_sr/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"t5-base\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(checkpoint)\n",
    "tokenizer = T5TokenizerFast.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.sep_token = '<sep>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32101, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(['<sep>'])\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_input_length =  512\n",
    "max_target_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenize the examples\n",
    "def convert_to_features(example_batch):\n",
    "\n",
    "    input_encodings = tokenizer.batch_encode_plus(example_batch['context'], \n",
    "                                                  max_length=max_input_length, \n",
    "                                                  add_special_tokens=True,\n",
    "                                                  truncation=True, \n",
    "                                                  pad_to_max_length=True)\n",
    "    \n",
    "    target_encodings = tokenizer.batch_encode_plus(example_batch['questions'], \n",
    "                                                   max_length=max_target_length, \n",
    "                                                   add_special_tokens=True,\n",
    "                                                   truncation=True, pad_to_max_length=True)\n",
    "                                                   \n",
    "    encodings = {\n",
    "        'input_ids': input_encodings['input_ids'], \n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'decoder_input_ids': target_encodings['input_ids']\n",
    "        ,'decoder_attention_mask': target_encodings['attention_mask']\n",
    "    }\n",
    "\n",
    "    return encodings\n",
    "\n",
    "def add_eos_examples(example):\n",
    "  example['context'] = example['context'] + \" </s>\"\n",
    "  example['questions'] = example['questions'] + \" </s>\"\n",
    "  return example\n",
    "\n",
    "\n",
    "def add_special_tokens(example):\n",
    "  example['questions'] = example['questions'].replace(\"{sep_token}\", '<sep>')\n",
    "  return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2478 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/826 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2478 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/826 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2478 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma/ma_ma/ma_ptyagi/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/826 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset  = raw_text.map(add_eos_examples)\n",
    "tokenized_dataset = tokenized_dataset.map(add_special_tokens)\n",
    "tokenized_dataset  = tokenized_dataset.map(convert_to_features,  batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Automated </s>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"][5][\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.remove_columns(\n",
    "    [\"context\", \"questions\"]\n",
    ")\n",
    "\n",
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "valid_dataset = tokenized_dataset[\"validation\"]\n",
    "\n",
    "columns = ['input_ids', 'decoder_input_ids', 'attention_mask', 'decoder_attention_mask']\n",
    "train_dataset.set_format(type='torch', columns=columns)\n",
    "valid_dataset.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(train_dataset, 'train_data.pt')\n",
    "torch.save(valid_dataset, 'valid_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This dataclass implementation is taken from Suraj Patil: https://github.com/patil-suraj/question_generation\n",
    "@dataclass\n",
    "class T2TDataCollator:\n",
    "  def __call__(self, batch: List) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Take a list of samples from a Dataset and collate them into a batch.\n",
    "    Returns:\n",
    "    A dictionary of tensors\n",
    "    \"\"\"\n",
    "    \n",
    "    input_ids = torch.stack([example['input_ids'] for example in batch])\n",
    "    lm_labels = torch.stack([example['decoder_input_ids'] for example in batch])\n",
    "    lm_labels[lm_labels[:, :] == 0] = -100 \n",
    "    attention_mask = torch.stack([example['attention_mask'] for example in batch])\n",
    "    decoder_attention_mask = torch.stack([example['decoder_attention_mask'] for example in batch])\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids, \n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': lm_labels, \n",
    "        'decoder_attention_mask': decoder_attention_mask\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma/ma_ma/ma_ptyagi/.local/lib/python3.9/site-packages/transformers/training_args.py:1469: FutureWarning: `--push_to_hub_model_id` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_model_id` instead and pass the full repo name to this argument (in this case prnv13/t5_flashcard_data).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir=\"models\", \n",
    "                                  per_device_train_batch_size=4, \n",
    "                                  per_device_eval_batch_size=4,\n",
    "                                  gradient_accumulation_steps=16,\n",
    "                                  learning_rate=1e-4, \n",
    "                                  num_train_epochs=7,\n",
    "                                  logging_steps=10,\n",
    "                                  run_name=\"end2end_flashcard_data\",\n",
    "                                  evaluation_strategy=\"steps\",\n",
    "                                  save_steps=50,\n",
    "                                  report_to=\"wandb\",\n",
    "                                  push_to_hub=True,\n",
    "                                  push_to_hub_model_id=\"t5_flashcard_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/prnv13/t5_flashcard_data into local empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma/ma_ma/ma_ptyagi/.local/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/pfs/data5/home/ma/ma_ma/ma_ptyagi/question_generation/wandb/run-20230503_083222-scwfwsb4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ankinator/t5-e2e/runs/scwfwsb4' target=\"_blank\">end2end_flashcard_data</a></strong> to <a href='https://wandb.ai/ankinator/t5-e2e' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ankinator/t5-e2e' target=\"_blank\">https://wandb.ai/ankinator/t5-e2e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ankinator/t5-e2e/runs/scwfwsb4' target=\"_blank\">https://wandb.ai/ankinator/t5-e2e/runs/scwfwsb4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 06:26, Epoch 6/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.074400</td>\n",
       "      <td>3.262558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.312800</td>\n",
       "      <td>2.955361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.062600</td>\n",
       "      <td>2.814604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.909700</td>\n",
       "      <td>2.761207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.870800</td>\n",
       "      <td>2.732137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.829800</td>\n",
       "      <td>2.718888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2023-03-24/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EOF\n",
      "error: failed to push some refs to 'https://huggingface.co/prnv13/t5_flashcard_data'\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "EOF\nerror: failed to push some refs to 'https://huggingface.co/prnv13/t5_flashcard_data'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)",
      "File \u001B[0;32m~/.local/lib/python3.9/site-packages/huggingface_hub/repository.py:1099\u001B[0m, in \u001B[0;36mRepository.git_push\u001B[0;34m(self, upstream, blocking, auto_lfs_prune)\u001B[0m\n\u001B[1;32m   1098\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m return_code:\n\u001B[0;32m-> 1099\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m subprocess\u001B[38;5;241m.\u001B[39mCalledProcessError(return_code, process\u001B[38;5;241m.\u001B[39margs, output\u001B[38;5;241m=\u001B[39mstdout, stderr\u001B[38;5;241m=\u001B[39mstderr)\n\u001B[1;32m   1101\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m subprocess\u001B[38;5;241m.\u001B[39mCalledProcessError \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "\u001B[0;31mCalledProcessError\u001B[0m: Command '['git', 'push', '--set-upstream', 'origin', 'main']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Training\u001B[39;00m\n\u001B[1;32m     13\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m---> 14\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpush_to_hub\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mt5_fd\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m wandb\u001B[38;5;241m.\u001B[39mfinish()\n",
      "File \u001B[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py:3661\u001B[0m, in \u001B[0;36mTrainer.push_to_hub\u001B[0;34m(self, commit_message, blocking, **kwargs)\u001B[0m\n\u001B[1;32m   3658\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpush_in_progress\u001B[38;5;241m.\u001B[39m_process\u001B[38;5;241m.\u001B[39mkill()\n\u001B[1;32m   3659\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpush_in_progress \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 3661\u001B[0m git_head_commit_url \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpush_to_hub\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3662\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcommit_message\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_message\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mblocking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mblocking\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauto_lfs_prune\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m   3663\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3664\u001B[0m \u001B[38;5;66;03m# push separately the model card to be independant from the rest of the model\u001B[39;00m\n\u001B[1;32m   3665\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mshould_save:\n",
      "File \u001B[0;32m~/.local/lib/python3.9/site-packages/huggingface_hub/repository.py:1307\u001B[0m, in \u001B[0;36mRepository.push_to_hub\u001B[0;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001B[0m\n\u001B[1;32m   1305\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgit_add(auto_lfs_track\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1306\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgit_commit(commit_message)\n\u001B[0;32m-> 1307\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgit_push\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1308\u001B[0m \u001B[43m    \u001B[49m\u001B[43mupstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43morigin \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_branch\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1309\u001B[0m \u001B[43m    \u001B[49m\u001B[43mblocking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mblocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1310\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauto_lfs_prune\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauto_lfs_prune\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1311\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.9/site-packages/huggingface_hub/repository.py:1102\u001B[0m, in \u001B[0;36mRepository.git_push\u001B[0;34m(self, upstream, blocking, auto_lfs_prune)\u001B[0m\n\u001B[1;32m   1099\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m subprocess\u001B[38;5;241m.\u001B[39mCalledProcessError(return_code, process\u001B[38;5;241m.\u001B[39margs, output\u001B[38;5;241m=\u001B[39mstdout, stderr\u001B[38;5;241m=\u001B[39mstderr)\n\u001B[1;32m   1101\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m subprocess\u001B[38;5;241m.\u001B[39mCalledProcessError \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(exc\u001B[38;5;241m.\u001B[39mstderr)\n\u001B[1;32m   1104\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m blocking:\n\u001B[1;32m   1106\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstatus_method\u001B[39m():\n",
      "\u001B[0;31mOSError\u001B[0m: EOF\nerror: failed to push some refs to 'https://huggingface.co/prnv13/t5_flashcard_data'\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize our Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=T2TDataCollator()\n",
    ")\n",
    "\n",
    "# Training\n",
    "trainer.train()\n",
    "trainer.push_to_hub(\"t5_fd\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T09:30:05.558440Z",
     "end_time": "2023-05-03T09:30:05.577353Z"
    }
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-03T09:30:07.314060Z",
     "end_time": "2023-05-03T09:30:07.320525Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_model(modell,input_string, **generator_args):\n",
    "  generator_args = {\n",
    "  \"max_length\": 256,\n",
    "  \"num_beams\": 4,\n",
    "  \"length_penalty\": 1.5,\n",
    "  \"no_repeat_ngram_size\": 3,\n",
    "  \"early_stopping\": True,\n",
    "  }\n",
    "  input_string = input_string + \" </s>\"\n",
    "  input_ids = tokenizer.encode(input_string, return_tensors=\"pt\")\n",
    "  res = modell.generate(input_ids, **generator_args)\n",
    "  output = tokenizer.batch_decode(res, skip_special_tokens=True)\n",
    "  output = [item.split(\"<sep>\") for item in output]\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-03T09:32:14.666895Z",
     "end_time": "2023-05-03T09:45:28.870683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e79433f59844c00864bf4de6709ec03"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "146dea0fa2884f399ff77325baa650e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hfmodel = T5ForConditionalGeneration.from_pretrained(\"prnv13/t5_flashcard_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-03T09:47:37.315819Z",
     "end_time": "2023-05-03T09:48:28.421906Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for c in test[\"context\"][1:100]:\n",
    "    predicted.append(run_model(hfmodel,c))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-03T09:48:42.318471Z",
     "end_time": "2023-05-03T09:48:42.324535Z"
    }
   },
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in predicted for subsublist in sublist for item in subsublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-03T09:48:43.295617Z",
     "end_time": "2023-05-03T09:48:43.310529Z"
    }
   },
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(flat_list, list(test[\"questions\"][1:100]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-03T09:48:44.015498Z",
     "end_time": "2023-05-03T09:48:44.020708Z"
    }
   },
   "outputs": [],
   "source": [
    "all_rouge_1_f1_scores = [pair_scores['rouge-1']['f'] for pair_scores in scores]\n",
    "average_rouge_1_f1_score = sum(all_rouge_1_f1_scores) / len(all_rouge_1_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-03T09:48:44.792884Z",
     "end_time": "2023-05-03T09:48:44.799222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.24900347385944305"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_rouge_1_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "['What is an EEF?',\n 'What is biotechnology?',\n 'What are the steps of creating a new app?',\n 'What is a restricted license?',\n 'What are successful prototypes and proofs of concept?',\n 'What is a quality management system?',\n 'What is a risk identification method?',\n 'Identify new configuration items (CIs)',\n 'What are the disadvantages of a change schedule?',\n 'What are the disadvantages of a NPO?',\n 'What are producercooperatives?',\n 'What is the difference between a singular and a plural?',\n 'What is a hacker?',\n 'What is tangible or non tangle output?',\n 'What are vectors and matrices?',\n 'What is an information system interface?',\n 'Represent the north south measurement of position.',\n 'What is a fingerprint?',\n 'What is a pointer?',\n 'What is pure demand paging?']"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_list[20:40]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T09:49:11.215112Z",
     "end_time": "2023-05-03T09:49:11.220798Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "['In the PESTLE model what does the letter ‚ÄúS‚Äù stand for?',\n 'What is Organizational Culture  Structure considered?',\n 'Name three industries where patents are very effective?',\n 'List 8 common operations on files:',\n 'Single user license',\n 'How do iterative life cycles improve the product or result?',\n 'Details of a control chart',\n 'What is the Delphi Technique?',\n 'List the service configuration processes:',\n 'Emergency changes may be implemented with less testing, is describing what?',\n 'What are advantages of charities? (5)',\n 'What are producer cooperatives?',\n 'How can we best name tables and views?',\n 'Hacker',\n 'What is a Product?',\n \"What abstract data types are required to implement the banker's algorithm?\",\n 'Graphical user interface GUI',\n 'Latitude',\n 'Biometrics',\n 'What is a file-system link?']"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test[\"questions\"])[20:40]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T09:49:12.089538Z",
     "end_time": "2023-05-03T09:49:12.095689Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "['Social',\n 'An EEF  it can have an effect on resource availability, how projects are selected, approved, conducted, etc., as well as PM authority and budget controls',\n 'Biotech,pharmaceuticals andchemicals',\n '1. Create2. Read3. Write4. Reposition5. Delete6. Truncate7. Append8. Rename',\n 'Restricts the use of the software to one user at a time',\n 'Success prototypes and proofs of concept',\n 'Tool and Technique of control qualityTracks repetitive activities or results',\n 'Anonymous risk identification method',\n 'Identify new configuration itemsAdd the CIs to the CMSUpdate configuration dataVerify record accuracyAudit applicationsAudit infrastructure',\n 'how changes should be handledEmergency changes are not typically included in a change schedule, and the process for assessment and authorization is expedited to ensure it can be implemented quickly. This means that sometimes the change is implemented with less testing as a result of time constraints.',\n '* Social benefits* Tax exemptions for NPOs* Tax incentives for donors* Limited liability* Public recognition and trust',\n 'They are cooperatives that join and support eachother to process or market their products. Farmercooperatives are a common example of producercooperatives.',\n 'Singular not plural.',\n 'Experts in technology who use their knowledge to break into computer and computer networks either for profit or simply for the challenge',\n 'Any tangible or non tangle output produced by a businessed that is purchased by either commercial or private customers',\n 'Vectors and matrices.',\n 'The interface to an information system',\n 'Represent the north south measurement of position',\n 'The identification of a user based on a physical characteristic such as a fingerprint iris face voice or handwriting',\n 'A pointer to another file or directory on a file-system.']"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test[\"context\"])[20:40]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T09:50:53.434269Z",
     "end_time": "2023-05-03T09:50:53.462872Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T10:06:47.464834Z",
     "end_time": "2023-05-03T10:08:28.422756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f021e46f1cd841cd9cc2dcc19413b2ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hmodel = T5ForConditionalGeneration.from_pretrained(\"prnv13/t5_qg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T10:08:57.032577Z",
     "end_time": "2023-05-03T10:09:46.602691Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for c in test[\"context\"][1:100]:\n",
    "    predicted.append(run_model(hmodel,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in predicted for subsublist in sublist for item in subsublist]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T10:09:46.607011Z",
     "end_time": "2023-05-03T10:09:46.609847Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(flat_list, list(test[\"questions\"][1:100]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T10:09:46.627283Z",
     "end_time": "2023-05-03T10:09:46.636433Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "all_rouge_1_f1_scores = [pair_scores['rouge-1']['f'] for pair_scores in scores]\n",
    "average_rouge_1_f1_score = sum(all_rouge_1_f1_scores) / len(all_rouge_1_f1_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T10:09:46.634234Z",
     "end_time": "2023-05-03T10:09:46.636635Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "0.2640314452593166"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_rouge_1_f1_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T10:09:46.638559Z",
     "end_time": "2023-05-03T10:09:46.667326Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "['What is an EEF?',\n 'Biotechnology,pharmaceuticals andchemicals',\n 'What are the steps of renaming a file?',\n 'What is a limitation of use?',\n 'What are successful prototypes and proofs of concept?',\n 'What is quality management?',\n 'What is a risk identification method?',\n 'What are the functions of a CMS?',\n 'What are the disadvantages of a change schedule?',\n 'What are the disadvantages of a NPO?',\n 'What are producercooperatives?',\n 'What is the difference between a syllable and a plural?',\n 'What are computer network engineers?',\n 'What is tangle output?',\n 'What are vectors and matrices?',\n 'What is a logical interface?',\n 'What is the North-South measurement of position?',\n 'What is fingerprint identification?',\n 'What is a pointer?',\n 'What is pure demand paging?']"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_list[20:40]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T10:09:46.661364Z",
     "end_time": "2023-05-03T10:09:46.667715Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "['In the PESTLE model what does the letter ‚ÄúS‚Äù stand for?',\n 'What is Organizational Culture  Structure considered?',\n 'Name three industries where patents are very effective?',\n 'List 8 common operations on files:',\n 'Single user license',\n 'How do iterative life cycles improve the product or result?',\n 'Details of a control chart',\n 'What is the Delphi Technique?',\n 'List the service configuration processes:',\n 'Emergency changes may be implemented with less testing, is describing what?',\n 'What are advantages of charities? (5)',\n 'What are producer cooperatives?',\n 'How can we best name tables and views?',\n 'Hacker',\n 'What is a Product?',\n \"What abstract data types are required to implement the banker's algorithm?\",\n 'Graphical user interface GUI',\n 'Latitude',\n 'Biometrics',\n 'What is a file-system link?']"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test[\"questions\"])[20:40]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T10:09:46.669611Z",
     "end_time": "2023-05-03T10:09:46.729139Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "['Social',\n 'An EEF  it can have an effect on resource availability, how projects are selected, approved, conducted, etc., as well as PM authority and budget controls',\n 'Biotech,pharmaceuticals andchemicals',\n '1. Create2. Read3. Write4. Reposition5. Delete6. Truncate7. Append8. Rename',\n 'Restricts the use of the software to one user at a time',\n 'Success prototypes and proofs of concept',\n 'Tool and Technique of control qualityTracks repetitive activities or results',\n 'Anonymous risk identification method',\n 'Identify new configuration itemsAdd the CIs to the CMSUpdate configuration dataVerify record accuracyAudit applicationsAudit infrastructure',\n 'how changes should be handledEmergency changes are not typically included in a change schedule, and the process for assessment and authorization is expedited to ensure it can be implemented quickly. This means that sometimes the change is implemented with less testing as a result of time constraints.',\n '* Social benefits* Tax exemptions for NPOs* Tax incentives for donors* Limited liability* Public recognition and trust',\n 'They are cooperatives that join and support eachother to process or market their products. Farmercooperatives are a common example of producercooperatives.',\n 'Singular not plural.',\n 'Experts in technology who use their knowledge to break into computer and computer networks either for profit or simply for the challenge',\n 'Any tangible or non tangle output produced by a businessed that is purchased by either commercial or private customers',\n 'Vectors and matrices.',\n 'The interface to an information system',\n 'Represent the north south measurement of position',\n 'The identification of a user based on a physical characteristic such as a fingerprint iris face voice or handwriting',\n 'A pointer to another file or directory on a file-system.']"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test[\"context\"])[20:40]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T10:09:46.690434Z",
     "end_time": "2023-05-03T10:09:46.743445Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
